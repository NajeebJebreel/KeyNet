{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from resnet_models import*\n",
    "import utils\n",
    "from utils import*\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import TensorDataset\n",
    "import mlp_private\n",
    "from mlp_private import*\n",
    "from dataset import BBoxDtaset\n",
    "import cv2\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import nni\n",
    "from nni.compression.torch import LevelPruner, L1FilterPruner, FPGMPruner, SlimPruner\n",
    "# from vgg_models import*\n",
    "from sklearn.metrics import *\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 100\n",
    "train_batch_size = 128\n",
    "test_batch_size = 100\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "original_classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "watermark_classes = ('no key', 'top righ', 'top left', 'down right', 'dwon left')\n",
    "identity_string = b'Y6588121SNAJEEBMOHARRAMSALIMJEBREEL02092020imageclassification_10_classes'\n",
    "fake_identity_string = b'Y6588121NAJEEBMOHARRAMSALIMcrisesURV02092020classification10labels'\n",
    "plagiarizer_identity_string = b'X7823579MRAMIJOSEPHAFFARcrisesURV2409022ResNet18classification10labels'\n",
    "plagiarizer_fake_identity_string = b'X7823579WRAMIHAFFARJOSEP2509022ResNet18classificationofImage10labels'\n",
    "key_size = 5\n",
    "num_wm_samples = 25000\n",
    "train_wm_black_box_epochs = 50\n",
    "combined_original_model_epochs = 200\n",
    "combined_private_model_epochs = 100\n",
    "train_simultaneously_epochs = 100\n",
    "dataset = 'cifar10'\n",
    "containerdataset = 'stl10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the original model on the original task\n",
    "def test_original_only(model, criterion, test_loader, device):\n",
    "   \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets, flags) in enumerate(test_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs= model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            print('Testing: epoch: %d | loss: %.3f | Acc: %.3f' %(1, test_loss/(batch_idx+1), 100.*correct/total))\n",
    "            \n",
    "        return  test_loss/(batch_idx+1), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the original model on the original task\n",
    "def test_original(model, criterion, test_loader, device):\n",
    "   \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets, flags) in enumerate(test_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs, _ = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            print('Testing: epoch: %d | loss: %.3f | Acc: %.3f' %(1, test_loss/(batch_idx+1), 100.*correct/total))\n",
    "            \n",
    "        return  test_loss/(batch_idx+1), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the private model on the wm task\n",
    "def test_private(model, criterion, test_loader, device):\n",
    "   \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets, flags) in enumerate(test_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                targets = targets.type(torch.LongTensor).to(device)\n",
    "                _, outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            print('Private model testing: epoch: %d | loss: %.3f | Acc: %.3f' %(1, test_loss/(batch_idx+1), 100.*correct/total))\n",
    "            \n",
    "            return  test_loss/(batch_idx+1), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the private model on the wm task\n",
    "def test_private_part(model, criterion, test_loader, device):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets, flags) in enumerate(test_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                targets = targets.type(torch.LongTensor).to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            print('Testing: epoch: %d | loss: %.3f | Acc: %.3f' %(1, test_loss/(batch_idx+1), 100.*correct/total))\n",
    "            \n",
    "        return  test_loss/(batch_idx+1), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]),   range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test label predictions\n",
    "def test_label_predictions_combined(test_loader, model, device):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "         for batch_idx, (inputs, targets, flags) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.type(torch.LongTensor).squeeze().to(device)\n",
    "            _, outputs = model(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "            prediction = outputs.argmax(dim=1, keepdim=True)\n",
    "            actuals.extend(targets.view_as(prediction))\n",
    "            predictions.extend(prediction)\n",
    "\n",
    "    actuals =  [i.item() for i in actuals]\n",
    "    predictions = [i.item() for i in predictions]\n",
    "    print('Confusion matrix:')\n",
    "    cnf_matrix = confusion_matrix(actuals, predictions)\n",
    "    print(cnf_matrix)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=[str(i) for i in range(6)], normalize=True,\n",
    "                      title='With predictions of unmarked VGG16')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('private_resnet18_with_unmarked_vgg16.png', dpi = 600)\n",
    "    plt.show()\n",
    "    print('F1 score: %f' % accuracy_score(actuals, predictions))\n",
    "\n",
    "    print('{0:10s} - {1}'.format('Category','Accuracy'))\n",
    "    for i, r in enumerate(confusion_matrix(actuals, predictions)):\n",
    "        print('{0:10s} - {1:.1f}'.format(str(i), r[i]/np.sum(r)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get the outputs of the original model to use them as input feature to the private model \n",
    "    that will be trained in a blackbox setting. \"\"\"\n",
    "def get_original_model_outputs(model, dataloader, device):\n",
    "        model.eval()\n",
    "        features = []\n",
    "        labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets, flags) in enumerate(dataloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                features.append(outputs)\n",
    "                labels.append(targets)\n",
    "    \n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get the outputs of the original model to use them as input feature to the private model \n",
    "    that will be trained in a blackbox setting. \"\"\"\n",
    "def get_wm_model_outputs(model, dataloader, device):\n",
    "        model.eval()\n",
    "        features = []\n",
    "        labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets, flags) in enumerate(dataloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs, _ = model(inputs)\n",
    "                features.append(outputs[0])\n",
    "                labels.append(targets)\n",
    "    \n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load original dataset\n",
    "\n",
    "trainset, testset, train_loader, test_loader = get_flagged_cifar10_dataset(100, 100)\n",
    "random_samples = np.random.choice(len(trainset), int(len(trainset)*1), replace = False)\n",
    "sampled_trainset = torch.utils.data.Subset(trainset, random_samples)\n",
    "finetune_train_loader = torch.utils.data.DataLoader(\n",
    "        sampled_trainset, batch_size=100, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load watermark dataset\n",
    "\n",
    "trainsetwm, testsetwm = get_signed_dataset(identity_string, fake_identity_string, key_size, num_wm_samples\n",
    "                                          , containerdataset=containerdataset)\n",
    "wm_testloader = torch.utils.data.DataLoader(testsetwm, batch_size=10, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "# wm_testloader = torch.utils.data.DataLoader(\n",
    "#         trainsetwm, batch_size=10, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of models\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18 = ResNet18().to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_original_cifar10.t7')\n",
    "resnet18.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "resnet18wm = ResNet18WM().to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_combined_fromscratch_cifar10.t7')\n",
    "resnet18wm.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "vgg16 = VGG('VGG16').to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_original_cifar10vgg16.t7')\n",
    "vgg16.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "vgg16wm = VGGWM('VGG16').to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_combined_fromscratch_cifar10vgg16.t7')\n",
    "vgg16wm.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_original(resnet18wm, criterion, test_loader, device)\n",
    "test_private(resnet18wm, criterion, wm_testloader, device) \n",
    "test_label_predictions_combined(wm_testloader, resnet18wm, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_original(vgg16wm, criterion, test_loader, device)\n",
    "test_private(vgg16wm, criterion, wm_testloader, device) \n",
    "test_label_predictions_combined(wm_testloader, vgg16wm, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrity experiments\n",
    "\n",
    "#1. Testing the private model trained with marked resnet18 with other unmarked resnet18\n",
    "print('Testing the private model trained with marked resnet18 with other unmarked resnet18')\n",
    "resnet18_dict = resnet18.state_dict()\n",
    "resnet18wm_dict = resnet18wm.state_dict()\n",
    "for key in resnet18_dict.keys():\n",
    "    resnet18wm_dict[key] = copy.deepcopy(resnet18_dict[key])\n",
    "\n",
    "resnet18wm.load_state_dict(resnet18wm_dict)\n",
    "# test_original(resnet18wm, criterion, test_loader, device)\n",
    "test_private(resnet18wm, criterion, wm_testloader, device) \n",
    "test_label_predictions_combined(wm_testloader, resnet18wm, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of models\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18 = ResNet18().to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_original_cifar10.t7')\n",
    "resnet18.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "resnet18wm = ResNet18WM().to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_combined_fromscratch_cifar10.t7')\n",
    "resnet18wm.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "vgg16 = VGG('VGG16').to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_original_cifar10vgg16.t7')\n",
    "vgg16.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "vgg16wm = VGGWM('VGG16').to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_combined_fromscratch_cifar10vgg16.t7')\n",
    "vgg16wm.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Testing the private model trained with marked resnet18 with other unmarked vgg16\n",
    "print('Testing the private model trained with marked resnet18 with other unmarked vgg16')\n",
    "vgg16_dict = vgg16.state_dict()\n",
    "vgg16wm_dict = vgg16wm.state_dict()\n",
    "resnet18wm_dict = resnet18wm.state_dict()\n",
    "\n",
    "\n",
    "vgg16wm_dict['wmlinear1.weight'] = copy.deepcopy(resnet18wm_dict['wmlayer1.weight'])\n",
    "vgg16wm_dict['wmlinear2.weight'] = copy.deepcopy(resnet18wm_dict['wmlayer2.weight'])\n",
    "vgg16wm_dict['wmlinear3.weight'] = copy.deepcopy(resnet18wm_dict['wmlayer3.weight'])\n",
    "vgg16wm_dict['wmlinear1.bias'] = copy.deepcopy(resnet18wm_dict['wmlayer1.bias'])\n",
    "vgg16wm_dict['wmlinear2.bias'] = copy.deepcopy(resnet18wm_dict['wmlayer2.bias'])\n",
    "vgg16wm_dict['wmlinear3.bias'] = copy.deepcopy(resnet18wm_dict['wmlayer3.bias'])\n",
    " \n",
    "\n",
    "for key in vgg16_dict.keys():\n",
    "    vgg16wm_dict[key] = copy.deepcopy(vgg16_dict[key])\n",
    "\n",
    "vgg16wm.load_state_dict(vgg16wm_dict)\n",
    "# test_original(vgg16wm, criterion, test_loader, device)\n",
    "test_private(vgg16wm, criterion, wm_testloader, device) \n",
    "test_label_predictions_combined(wm_testloader, vgg16wm, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of models\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18 = ResNet18().to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_original_cifar10.t7')\n",
    "resnet18.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "resnet18wm = ResNet18WM().to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_combined_fromscratch_cifar10.t7')\n",
    "resnet18wm.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "vgg16 = VGG('VGG16').to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_original_cifar10vgg16.t7')\n",
    "vgg16.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "vgg16wm = VGGWM('VGG16').to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_combined_fromscratch_cifar10vgg16.t7')\n",
    "vgg16wm.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Testing the private model trained with marked vgg16 with other unmarked vgg16\n",
    "print('Testing the private model trained with marked vgg16 with other unmarked vgg16')\n",
    "vgg16_dict = vgg16.state_dict()\n",
    "vgg16wm_dict = vgg16wm.state_dict()\n",
    "for key in vgg16_dict.keys():\n",
    "    vgg16wm_dict[key] = copy.deepcopy(vgg16_dict[key])\n",
    "\n",
    "vgg16wm.load_state_dict(vgg16wm_dict)\n",
    "# test_original(vgg16wm, criterion, test_loader, device)\n",
    "test_private(vgg16wm, criterion, wm_testloader, device) \n",
    "test_label_predictions_combined(wm_testloader, vgg16wm, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of models\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18 = ResNet18().to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_original_cifar10.t7')\n",
    "resnet18.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "resnet18wm = ResNet18WM().to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_combined_fromscratch_cifar10.t7')\n",
    "resnet18wm.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "vgg16 = VGG('VGG16').to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_original_cifar10vgg16.t7')\n",
    "vgg16.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "vgg16wm = VGGWM('VGG16').to(device)\n",
    "checkpoint = torch.load('./Checkpoints/best_combined_fromscratch_cifar10vgg16.t7')\n",
    "vgg16wm.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Testing the private model trained with marked vgg16 with other unmarked resnet18\n",
    "print('Testing the private model trained with marked vgg16 with other unmarked resnet18')\n",
    "\n",
    "vgg16wm_dict = vgg16wm.state_dict()\n",
    "resnet18_dict = resnet18.state_dict()\n",
    "resnet18wm_dict = resnet18wm.state_dict()\n",
    "\n",
    "\n",
    "\n",
    "resnet18wm_dict['wmlayer1.weight'] = copy.deepcopy(vgg16wm_dict['wmlinear1.weight'])\n",
    "resnet18wm_dict['wmlayer2.weight'] = copy.deepcopy(vgg16wm_dict['wmlinear2.weight'])\n",
    "resnet18wm_dict['wmlayer3.weight'] = copy.deepcopy(vgg16wm_dict['wmlinear3.weight'])\n",
    "resnet18wm_dict['wmlayer1.bias'] = copy.deepcopy(vgg16wm_dict['wmlinear1.bias'])\n",
    "resnet18wm_dict['wmlayer2.bias'] = copy.deepcopy(vgg16wm_dict['wmlinear2.bias'])\n",
    "resnet18wm_dict['wmlayer3.bias'] = copy.deepcopy(vgg16wm_dict['wmlinear3.bias'])\n",
    " \n",
    "\n",
    "for key in resnet18_dict.keys():\n",
    "    resnet18wm_dict[key] = copy.deepcopy(resnet18_dict[key])\n",
    "\n",
    "resnet18wm.load_state_dict(resnet18wm_dict)\n",
    "# test_original(resnet18wm, criterion, test_loader, device)\n",
    "test_private(resnet18wm, criterion, wm_testloader, device) \n",
    "test_label_predictions_combined(wm_testloader, resnet18wm, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_models import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18WM()\n",
    "y = net(torch.randn(1, 3, 32, 32))\n",
    "print(y[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('./data/dif_dist/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmtrainset, wmtestset = get_signed_diff_dist(identity_string = identity_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eb9960f220>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = wmtestset[50][0].numpy()\n",
    "y = np.transpose(x, (1, 2, 0))\n",
    "plt.imshow(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
