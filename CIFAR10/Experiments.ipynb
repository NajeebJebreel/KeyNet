{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keynet import KeyNet\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Original task data loading..\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> CIFAR 10 original dataset has been loaded.\n",
      "==>> Watermark task data loading..\n",
      "Files already downloaded and verified\n",
      "==> Watermarked dataset has been loaded.\n",
      "==> Building models of cifar10 with VGG16\n",
      "\n",
      "==> Models built..\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "original_task_train_epochs = 250\n",
    "train_batch_size = 128\n",
    "test_batch_size = 100\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "\n",
    "original_classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "watermark_classes = ('not signed', 'top righ', 'top left', 'down right', 'dwon left', 'center')\n",
    "\n",
    "owner_identity_string = b'Y123456789S_CRISES_URV_DEIM_NAJEEBMOHARRAMSALIMJEBREEL02092020imageclassification_ResNet18_10_classes'\n",
    "attacker_identity_string = b'X7823579_CRISES_URV_DEIM_MRAMIJOSEPHAFFAR_crisesURV_2409022_ResNet18_Objectclassification_10labels'\n",
    "signature_size = 25\n",
    "train_wm_black_box_epochs = 250\n",
    "embedwm_byfinetuning_epochs = 30\n",
    "embedwm_fromscratch_epochs = 25\n",
    "\n",
    "finetuning_attack_epochs = [50, 100, 150, 200]\n",
    "wm_overite_epochs = 50\n",
    "original_dataset = 'cifar10'\n",
    "wmcarrierset = 'stl10'\n",
    "attacker_wmcarrierset = 'fmnist'\n",
    "model_names = ['ResNet18', 'VGG16']\n",
    "seed = 123\n",
    "\n",
    "\n",
    "keynet = KeyNet(device, original_task_train_epochs = original_task_train_epochs, train_batch_size = train_batch_size, \n",
    "                test_batch_size = test_batch_size, learning_rate = learning_rate, momentum = momentum,\n",
    "                original_classes = original_classes, owner_identity_string = owner_identity_string, \n",
    "                attacker_identity_string = attacker_identity_string,\n",
    "                signature_size = signature_size, train_wm_black_box_epochs = train_wm_black_box_epochs, \n",
    "                embedwm_byfinetuning_epochs = embedwm_byfinetuning_epochs,\n",
    "                embedwm_fromscratch_epochs = embedwm_fromscratch_epochs, \n",
    "                finetuning_attack_epochs = finetuning_attack_epochs, wm_overite_epochs = wm_overite_epochs,\n",
    "                original_dataset = original_dataset, wmcarrierset = wmcarrierset, \n",
    "                attacker_wmcarrierset = attacker_wmcarrierset, model_name = model_names[1], seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a6727909da45b39285b59a438740dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: loss: 1.447 | Acc: 46.750\n",
      "Testing: loss: 1.133 | Acc: 59.040\n",
      "\n",
      "Training: loss: 1.011 | Acc: 63.830\n",
      "Testing: loss: 0.953 | Acc: 66.750\n",
      "\n",
      "Training: loss: 0.818 | Acc: 71.034\n",
      "Testing: loss: 0.857 | Acc: 70.920\n",
      "\n",
      "Training: loss: 0.713 | Acc: 74.982\n",
      "Testing: loss: 0.693 | Acc: 75.750\n",
      "\n",
      "Training: loss: 0.640 | Acc: 77.238\n",
      "Testing: loss: 0.725 | Acc: 75.070\n",
      "\n",
      "Training: loss: 0.576 | Acc: 79.826\n",
      "Testing: loss: 0.589 | Acc: 79.830\n",
      "\n",
      "Training: loss: 0.529 | Acc: 81.540\n",
      "Testing: loss: 0.630 | Acc: 79.020\n",
      "\n",
      "Training: loss: 0.493 | Acc: 82.800\n",
      "Testing: loss: 0.595 | Acc: 79.960\n",
      "\n",
      "Training: loss: 0.456 | Acc: 84.108\n",
      "Testing: loss: 0.551 | Acc: 81.150\n",
      "\n",
      "Training: loss: 0.424 | Acc: 85.152\n",
      "Testing: loss: 0.541 | Acc: 82.000\n",
      "\n",
      "Training: loss: 0.400 | Acc: 86.094\n",
      "Testing: loss: 0.515 | Acc: 83.010\n",
      "\n",
      "Training: loss: 0.375 | Acc: 86.932\n",
      "Testing: loss: 0.577 | Acc: 81.070\n",
      "\n",
      "Training: loss: 0.354 | Acc: 87.602\n",
      "Testing: loss: 0.519 | Acc: 83.070\n",
      "\n",
      "Training: loss: 0.330 | Acc: 88.528\n",
      "Testing: loss: 0.521 | Acc: 83.190\n",
      "\n",
      "Training: loss: 0.322 | Acc: 88.710\n",
      "Testing: loss: 0.443 | Acc: 85.370\n",
      "\n",
      "Training: loss: 0.297 | Acc: 89.586\n",
      "Testing: loss: 0.452 | Acc: 85.060\n",
      "\n",
      "Training: loss: 0.277 | Acc: 90.314\n",
      "Testing: loss: 0.453 | Acc: 85.170\n",
      "\n",
      "Training: loss: 0.265 | Acc: 90.702\n",
      "Testing: loss: 0.484 | Acc: 84.480\n",
      "\n",
      "Training: loss: 0.257 | Acc: 91.034\n",
      "Testing: loss: 0.478 | Acc: 84.940\n",
      "\n",
      "Training: loss: 0.247 | Acc: 91.298\n",
      "Testing: loss: 0.459 | Acc: 85.490\n",
      "\n",
      "Training: loss: 0.228 | Acc: 91.930\n",
      "Testing: loss: 0.419 | Acc: 86.910\n",
      "\n",
      "Training: loss: 0.219 | Acc: 92.310\n",
      "Testing: loss: 0.460 | Acc: 85.600\n",
      "\n",
      "Training: loss: 0.206 | Acc: 92.806\n",
      "Testing: loss: 0.470 | Acc: 85.670\n",
      "\n",
      "Training: loss: 0.193 | Acc: 93.286\n",
      "Testing: loss: 0.479 | Acc: 85.770\n",
      "\n",
      "Training: loss: 0.191 | Acc: 93.212\n",
      "Testing: loss: 0.504 | Acc: 85.370\n",
      "\n",
      "Training: loss: 0.179 | Acc: 93.722\n",
      "Testing: loss: 0.425 | Acc: 87.050\n",
      "\n",
      "Training: loss: 0.167 | Acc: 94.120\n",
      "Testing: loss: 0.442 | Acc: 86.750\n",
      "\n",
      "Training: loss: 0.161 | Acc: 94.390\n",
      "Testing: loss: 0.467 | Acc: 85.960\n",
      "\n",
      "Training: loss: 0.155 | Acc: 94.594\n",
      "Testing: loss: 0.420 | Acc: 87.150\n",
      "\n",
      "Training: loss: 0.145 | Acc: 94.908\n",
      "Testing: loss: 0.453 | Acc: 86.320\n",
      "\n",
      "Training: loss: 0.142 | Acc: 95.004\n",
      "Testing: loss: 0.440 | Acc: 87.080\n",
      "\n",
      "Training: loss: 0.134 | Acc: 95.210\n",
      "Testing: loss: 0.492 | Acc: 86.170\n",
      "\n",
      "Training: loss: 0.131 | Acc: 95.426\n",
      "Testing: loss: 0.431 | Acc: 87.630\n",
      "\n",
      "Training: loss: 0.117 | Acc: 95.884\n",
      "Testing: loss: 0.452 | Acc: 87.280\n",
      "\n",
      "Training: loss: 0.113 | Acc: 96.054\n",
      "Testing: loss: 0.462 | Acc: 87.240\n",
      "\n",
      "Training: loss: 0.117 | Acc: 95.822\n",
      "Testing: loss: 0.476 | Acc: 86.680\n",
      "\n",
      "Training: loss: 0.109 | Acc: 96.238\n",
      "Testing: loss: 0.456 | Acc: 87.470\n",
      "\n",
      "Training: loss: 0.105 | Acc: 96.278\n",
      "Testing: loss: 0.485 | Acc: 86.930\n",
      "\n",
      "Training: loss: 0.097 | Acc: 96.604\n",
      "Testing: loss: 0.471 | Acc: 87.480\n",
      "\n",
      "Training: loss: 0.094 | Acc: 96.656\n",
      "Testing: loss: 0.467 | Acc: 87.220\n",
      "\n",
      "Training: loss: 0.089 | Acc: 96.896\n",
      "Testing: loss: 0.496 | Acc: 86.950\n",
      "\n",
      "Training: loss: 0.087 | Acc: 96.970\n",
      "Testing: loss: 0.465 | Acc: 87.650\n",
      "\n",
      "Training: loss: 0.087 | Acc: 96.934\n",
      "Testing: loss: 0.469 | Acc: 87.350\n",
      "\n",
      "Training: loss: 0.083 | Acc: 97.030\n",
      "Testing: loss: 0.485 | Acc: 87.640\n",
      "\n",
      "Training: loss: 0.077 | Acc: 97.314\n",
      "Testing: loss: 0.494 | Acc: 87.260\n",
      "\n",
      "Training: loss: 0.077 | Acc: 97.282\n",
      "Testing: loss: 0.471 | Acc: 87.660\n",
      "\n",
      "Training: loss: 0.076 | Acc: 97.228\n",
      "Testing: loss: 0.459 | Acc: 88.170\n",
      "\n",
      "Training: loss: 0.069 | Acc: 97.582\n",
      "Testing: loss: 0.497 | Acc: 87.460\n",
      "\n",
      "Training: loss: 0.068 | Acc: 97.614\n",
      "Testing: loss: 0.479 | Acc: 87.650\n",
      "\n",
      "Training: loss: 0.066 | Acc: 97.704\n",
      "Testing: loss: 0.466 | Acc: 88.430\n",
      "\n",
      "Training: loss: 0.064 | Acc: 97.738\n",
      "Testing: loss: 0.466 | Acc: 88.710\n",
      "\n",
      "Training: loss: 0.059 | Acc: 97.970\n",
      "Testing: loss: 0.486 | Acc: 88.070\n",
      "\n",
      "Training: loss: 0.059 | Acc: 97.864\n",
      "Testing: loss: 0.483 | Acc: 87.970\n",
      "\n",
      "Training: loss: 0.062 | Acc: 97.898\n",
      "Testing: loss: 0.453 | Acc: 88.780\n",
      "\n",
      "Training: loss: 0.055 | Acc: 98.048\n",
      "Testing: loss: 0.480 | Acc: 88.470\n",
      "\n",
      "Training: loss: 0.055 | Acc: 98.086\n",
      "Testing: loss: 0.495 | Acc: 88.090\n",
      "\n",
      "Training: loss: 0.050 | Acc: 98.320\n",
      "Testing: loss: 0.461 | Acc: 88.710\n",
      "\n",
      "Training: loss: 0.052 | Acc: 98.182\n",
      "Testing: loss: 0.488 | Acc: 88.160\n",
      "\n",
      "Training: loss: 0.049 | Acc: 98.298\n",
      "Testing: loss: 0.464 | Acc: 88.460\n",
      "\n",
      "Training: loss: 0.047 | Acc: 98.378\n",
      "Testing: loss: 0.486 | Acc: 88.540\n",
      "\n",
      "Training: loss: 0.044 | Acc: 98.486\n",
      "Testing: loss: 0.514 | Acc: 88.590\n",
      "\n",
      "Training: loss: 0.043 | Acc: 98.494\n",
      "Testing: loss: 0.485 | Acc: 88.590\n",
      "\n",
      "Training: loss: 0.048 | Acc: 98.334\n",
      "Testing: loss: 0.493 | Acc: 88.070\n",
      "\n",
      "Training: loss: 0.046 | Acc: 98.416\n",
      "Testing: loss: 0.469 | Acc: 88.830\n",
      "\n",
      "Training: loss: 0.046 | Acc: 98.412\n",
      "Testing: loss: 0.499 | Acc: 88.450\n",
      "\n",
      "Training: loss: 0.043 | Acc: 98.442\n",
      "Testing: loss: 0.526 | Acc: 88.040\n",
      "\n",
      "Training: loss: 0.044 | Acc: 98.364\n",
      "Testing: loss: 0.516 | Acc: 88.520\n",
      "\n",
      "Training: loss: 0.042 | Acc: 98.546\n",
      "Testing: loss: 0.508 | Acc: 88.360\n",
      "\n",
      "Training: loss: 0.041 | Acc: 98.562\n",
      "Testing: loss: 0.476 | Acc: 88.950\n",
      "\n",
      "Training: loss: 0.037 | Acc: 98.704\n",
      "Testing: loss: 0.478 | Acc: 89.090\n",
      "\n",
      "Training: loss: 0.039 | Acc: 98.624\n",
      "Testing: loss: 0.488 | Acc: 88.720\n",
      "\n",
      "Training: loss: 0.037 | Acc: 98.708\n",
      "Testing: loss: 0.485 | Acc: 88.990\n",
      "\n",
      "Training: loss: 0.035 | Acc: 98.752\n",
      "Testing: loss: 0.471 | Acc: 89.160\n",
      "\n",
      "Training: loss: 0.034 | Acc: 98.796\n",
      "Testing: loss: 0.462 | Acc: 89.450\n",
      "\n",
      "Training: loss: 0.033 | Acc: 98.844\n",
      "Testing: loss: 0.500 | Acc: 88.900\n",
      "\n",
      "Training: loss: 0.033 | Acc: 98.872\n",
      "Testing: loss: 0.483 | Acc: 89.040\n",
      "\n",
      "Training: loss: 0.034 | Acc: 98.832\n",
      "Testing: loss: 0.495 | Acc: 88.870\n",
      "\n",
      "Training: loss: 0.032 | Acc: 98.876\n",
      "Testing: loss: 0.486 | Acc: 89.190\n",
      "\n",
      "Training: loss: 0.033 | Acc: 98.876\n",
      "Testing: loss: 0.476 | Acc: 89.420\n",
      "\n",
      "Training: loss: 0.031 | Acc: 98.896\n",
      "Testing: loss: 0.478 | Acc: 89.160\n",
      "\n",
      "Training: loss: 0.032 | Acc: 98.832\n",
      "Testing: loss: 0.507 | Acc: 88.700\n",
      "\n",
      "Training: loss: 0.030 | Acc: 98.950\n",
      "Testing: loss: 0.482 | Acc: 89.350\n",
      "\n",
      "Training: loss: 0.027 | Acc: 99.032\n",
      "Testing: loss: 0.526 | Acc: 88.630\n",
      "\n",
      "Training: loss: 0.025 | Acc: 99.134\n",
      "Testing: loss: 0.482 | Acc: 89.220\n",
      "\n",
      "Training: loss: 0.025 | Acc: 99.106\n",
      "Testing: loss: 0.489 | Acc: 89.040\n",
      "\n",
      "Training: loss: 0.026 | Acc: 99.064\n",
      "Testing: loss: 0.490 | Acc: 89.310\n",
      "\n",
      "Training: loss: 0.028 | Acc: 99.052\n",
      "Testing: loss: 0.489 | Acc: 89.540\n",
      "\n",
      "Training: loss: 0.024 | Acc: 99.178\n",
      "Testing: loss: 0.498 | Acc: 89.110\n",
      "\n",
      "Training: loss: 0.027 | Acc: 99.076\n",
      "Testing: loss: 0.495 | Acc: 89.200\n",
      "\n",
      "Training: loss: 0.024 | Acc: 99.170\n",
      "Testing: loss: 0.501 | Acc: 88.950\n",
      "\n",
      "Training: loss: 0.026 | Acc: 99.064\n",
      "Testing: loss: 0.459 | Acc: 89.860\n",
      "\n",
      "Training: loss: 0.027 | Acc: 99.038\n",
      "Testing: loss: 0.510 | Acc: 88.620\n",
      "\n",
      "Training: loss: 0.024 | Acc: 99.200\n",
      "Testing: loss: 0.503 | Acc: 88.970\n",
      "\n",
      "Training: loss: 0.022 | Acc: 99.248\n",
      "Testing: loss: 0.496 | Acc: 89.640\n",
      "\n",
      "Training: loss: 0.020 | Acc: 99.324\n",
      "Testing: loss: 0.494 | Acc: 89.240\n",
      "\n",
      "Training: loss: 0.026 | Acc: 99.106\n",
      "Testing: loss: 0.498 | Acc: 89.430\n",
      "\n",
      "Training: loss: 0.024 | Acc: 99.182\n",
      "Testing: loss: 0.490 | Acc: 89.390\n",
      "\n",
      "Training: loss: 0.023 | Acc: 99.246\n",
      "Testing: loss: 0.486 | Acc: 89.270\n",
      "\n",
      "Training: loss: 0.022 | Acc: 99.266\n",
      "Testing: loss: 0.496 | Acc: 89.630\n",
      "\n",
      "Training: loss: 0.023 | Acc: 99.206\n",
      "Testing: loss: 0.483 | Acc: 89.730\n",
      "\n",
      "Training: loss: 0.024 | Acc: 99.138\n",
      "Testing: loss: 0.513 | Acc: 88.660\n",
      "\n",
      "Training: loss: 0.025 | Acc: 99.138\n",
      "Testing: loss: 0.504 | Acc: 89.120\n",
      "\n",
      "Training: loss: 0.023 | Acc: 99.198\n",
      "Testing: loss: 0.485 | Acc: 89.700\n",
      "\n",
      "Training: loss: 0.020 | Acc: 99.282\n",
      "Testing: loss: 0.528 | Acc: 89.110\n",
      "\n",
      "Training: loss: 0.021 | Acc: 99.276\n",
      "Testing: loss: 0.502 | Acc: 89.400\n",
      "\n",
      "Training: loss: 0.020 | Acc: 99.320\n",
      "Testing: loss: 0.481 | Acc: 89.990\n",
      "\n",
      "Training: loss: 0.020 | Acc: 99.322\n",
      "Testing: loss: 0.498 | Acc: 89.620\n",
      "\n",
      "Training: loss: 0.018 | Acc: 99.426\n",
      "Testing: loss: 0.501 | Acc: 89.310\n",
      "\n",
      "Training: loss: 0.020 | Acc: 99.340\n",
      "Testing: loss: 0.476 | Acc: 89.530\n",
      "\n",
      "Training: loss: 0.020 | Acc: 99.330\n",
      "Testing: loss: 0.495 | Acc: 89.370\n",
      "\n",
      "Training: loss: 0.020 | Acc: 99.308\n",
      "Testing: loss: 0.513 | Acc: 89.250\n",
      "\n",
      "Training: loss: 0.020 | Acc: 99.320\n",
      "Testing: loss: 0.516 | Acc: 89.200\n",
      "\n",
      "Training: loss: 0.017 | Acc: 99.460\n",
      "Testing: loss: 0.486 | Acc: 89.510\n",
      "\n",
      "Training: loss: 0.016 | Acc: 99.488\n",
      "Testing: loss: 0.513 | Acc: 88.960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: loss: 0.016 | Acc: 99.500\n",
      "Testing: loss: 0.501 | Acc: 89.400\n",
      "\n",
      "Training: loss: 0.019 | Acc: 99.326\n",
      "Testing: loss: 0.522 | Acc: 88.960\n",
      "\n",
      "Training: loss: 0.017 | Acc: 99.442\n",
      "Testing: loss: 0.499 | Acc: 89.590\n",
      "\n",
      "Training: loss: 0.015 | Acc: 99.452\n",
      "Testing: loss: 0.528 | Acc: 89.010\n",
      "\n",
      "Training: loss: 0.017 | Acc: 99.414\n",
      "Testing: loss: 0.505 | Acc: 89.590\n",
      "\n",
      "Training: loss: 0.019 | Acc: 99.350\n",
      "Testing: loss: 0.520 | Acc: 89.270\n",
      "\n",
      "Training: loss: 0.019 | Acc: 99.352\n",
      "Testing: loss: 0.510 | Acc: 89.010\n",
      "\n",
      "Training: loss: 0.020 | Acc: 99.292\n",
      "Testing: loss: 0.483 | Acc: 89.780\n",
      "\n",
      "Training: loss: 0.019 | Acc: 99.332\n",
      "Testing: loss: 0.506 | Acc: 89.090\n",
      "\n",
      "Training: loss: 0.017 | Acc: 99.426\n",
      "Testing: loss: 0.497 | Acc: 89.350\n",
      "\n",
      "Training: loss: 0.017 | Acc: 99.414\n",
      "Testing: loss: 0.473 | Acc: 89.810\n",
      "\n",
      "Training: loss: 0.015 | Acc: 99.482\n",
      "Testing: loss: 0.485 | Acc: 89.910\n",
      "\n",
      "Training: loss: 0.015 | Acc: 99.444\n",
      "Testing: loss: 0.491 | Acc: 89.790\n",
      "\n",
      "Training: loss: 0.014 | Acc: 99.550\n",
      "Testing: loss: 0.506 | Acc: 89.110\n",
      "\n",
      "Training: loss: 0.015 | Acc: 99.510\n",
      "Testing: loss: 0.519 | Acc: 89.480\n",
      "\n",
      "Training: loss: 0.018 | Acc: 99.420\n",
      "Testing: loss: 0.492 | Acc: 89.960\n",
      "\n",
      "Training: loss: 0.016 | Acc: 99.448\n",
      "Testing: loss: 0.526 | Acc: 89.490\n",
      "\n",
      "Training: loss: 0.015 | Acc: 99.490\n",
      "Testing: loss: 0.498 | Acc: 90.060\n",
      "\n",
      "Training: loss: 0.018 | Acc: 99.382\n",
      "Testing: loss: 0.493 | Acc: 89.780\n",
      "\n",
      "Training: loss: 0.016 | Acc: 99.440\n",
      "Testing: loss: 0.501 | Acc: 89.810\n",
      "\n",
      "Training: loss: 0.017 | Acc: 99.446\n",
      "Testing: loss: 0.511 | Acc: 89.600\n",
      "\n",
      "Training: loss: 0.017 | Acc: 99.416\n",
      "Testing: loss: 0.495 | Acc: 90.040\n",
      "\n",
      "Training: loss: 0.016 | Acc: 99.504\n",
      "Testing: loss: 0.498 | Acc: 89.960\n",
      "\n",
      "Training: loss: 0.017 | Acc: 99.436\n",
      "Testing: loss: 0.508 | Acc: 89.870\n",
      "\n",
      "Training: loss: 0.011 | Acc: 99.650\n",
      "Testing: loss: 0.505 | Acc: 89.870\n",
      "\n",
      "Training: loss: 0.014 | Acc: 99.544\n",
      "Testing: loss: 0.529 | Acc: 89.600\n",
      "\n",
      "Training: loss: 0.016 | Acc: 99.456\n",
      "Testing: loss: 0.504 | Acc: 89.630\n",
      "\n",
      "Training: loss: 0.018 | Acc: 99.414\n",
      "Testing: loss: 0.499 | Acc: 89.850\n",
      "\n",
      "Training: loss: 0.015 | Acc: 99.520\n",
      "Testing: loss: 0.491 | Acc: 89.750\n",
      "\n",
      "Training: loss: 0.013 | Acc: 99.568\n",
      "Testing: loss: 0.541 | Acc: 89.330\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.592\n",
      "Testing: loss: 0.520 | Acc: 89.240\n",
      "\n",
      "Training: loss: 0.013 | Acc: 99.530\n",
      "Testing: loss: 0.478 | Acc: 89.940\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.604\n",
      "Testing: loss: 0.500 | Acc: 89.770\n",
      "\n",
      "Training: loss: 0.010 | Acc: 99.696\n",
      "Testing: loss: 0.485 | Acc: 90.020\n",
      "\n",
      "Training: loss: 0.013 | Acc: 99.550\n",
      "Testing: loss: 0.533 | Acc: 89.130\n",
      "\n",
      "Training: loss: 0.014 | Acc: 99.544\n",
      "Testing: loss: 0.503 | Acc: 89.640\n",
      "\n",
      "Training: loss: 0.011 | Acc: 99.632\n",
      "Testing: loss: 0.518 | Acc: 89.420\n",
      "\n",
      "Training: loss: 0.015 | Acc: 99.510\n",
      "Testing: loss: 0.522 | Acc: 89.600\n",
      "\n",
      "Training: loss: 0.015 | Acc: 99.504\n",
      "Testing: loss: 0.504 | Acc: 89.780\n",
      "\n",
      "Training: loss: 0.014 | Acc: 99.526\n",
      "Testing: loss: 0.512 | Acc: 89.510\n",
      "\n",
      "Training: loss: 0.013 | Acc: 99.568\n",
      "Testing: loss: 0.494 | Acc: 90.140\n",
      "\n",
      "Training: loss: 0.017 | Acc: 99.402\n",
      "Testing: loss: 0.481 | Acc: 90.030\n",
      "\n",
      "Training: loss: 0.014 | Acc: 99.542\n",
      "Testing: loss: 0.514 | Acc: 89.650\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.622\n",
      "Testing: loss: 0.502 | Acc: 89.760\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.600\n",
      "Testing: loss: 0.489 | Acc: 90.090\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.580\n",
      "Testing: loss: 0.547 | Acc: 89.240\n",
      "\n",
      "Training: loss: 0.011 | Acc: 99.618\n",
      "Testing: loss: 0.508 | Acc: 89.570\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.608\n",
      "Testing: loss: 0.514 | Acc: 89.950\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.568\n",
      "Testing: loss: 0.506 | Acc: 89.510\n",
      "\n",
      "Training: loss: 0.011 | Acc: 99.638\n",
      "Testing: loss: 0.497 | Acc: 89.810\n",
      "\n",
      "Training: loss: 0.013 | Acc: 99.538\n",
      "Testing: loss: 0.497 | Acc: 89.940\n",
      "\n",
      "Training: loss: 0.014 | Acc: 99.532\n",
      "Testing: loss: 0.499 | Acc: 89.730\n",
      "\n",
      "Training: loss: 0.014 | Acc: 99.528\n",
      "Testing: loss: 0.476 | Acc: 89.910\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.610\n",
      "Testing: loss: 0.495 | Acc: 89.820\n",
      "\n",
      "Training: loss: 0.011 | Acc: 99.630\n",
      "Testing: loss: 0.496 | Acc: 90.000\n",
      "\n",
      "Training: loss: 0.013 | Acc: 99.558\n",
      "Testing: loss: 0.493 | Acc: 90.020\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.602\n",
      "Testing: loss: 0.479 | Acc: 89.760\n",
      "\n",
      "Training: loss: 0.009 | Acc: 99.728\n",
      "Testing: loss: 0.485 | Acc: 90.010\n",
      "\n",
      "Training: loss: 0.011 | Acc: 99.636\n",
      "Testing: loss: 0.501 | Acc: 89.990\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.650\n",
      "Testing: loss: 0.492 | Acc: 90.280\n",
      "\n",
      "Training: loss: 0.013 | Acc: 99.552\n",
      "Testing: loss: 0.499 | Acc: 89.880\n",
      "\n",
      "Training: loss: 0.015 | Acc: 99.500\n",
      "Testing: loss: 0.485 | Acc: 89.590\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.604\n",
      "Testing: loss: 0.514 | Acc: 89.570\n",
      "\n",
      "Training: loss: 0.014 | Acc: 99.538\n",
      "Testing: loss: 0.494 | Acc: 89.900\n",
      "\n",
      "Training: loss: 0.011 | Acc: 99.616\n",
      "Testing: loss: 0.498 | Acc: 89.800\n",
      "\n",
      "Training: loss: 0.012 | Acc: 99.604\n",
      "Testing: loss: 0.515 | Acc: 89.610\n",
      "\n",
      "Training: loss: 0.010 | Acc: 99.694\n",
      "Testing: loss: 0.490 | Acc: 90.240\n"
     ]
    }
   ],
   "source": [
    "keynet.train_original_task(epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keynet.train_original_task(resume = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keynet.train_private_model_with_black_box_access(train_wm_black_box_epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keynet.embedwm_byfinetuning(train_private_model_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keynet.finetune_original_part(finetuning_epochs = 200, model_name = 'fintuned', data_fraction = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keynet.embedwm_fromscratch(train_fromscratch_epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keynet.finetune_original_part(finetuning_epochs=200, model_name = 'fromscratch', data_fraction = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fraction = [0.01, 0.03, 0.05, 0.1, 0.15]\n",
    "for fraction in data_fraction:\n",
    "    print('Fraction of training data: {}%'.format(fraction*100))\n",
    "    keynet.overwrite_watermark(wm_overite_epochs = wm_overite_epochs, model_name = 'fromscratch', data_fraction = fraction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
